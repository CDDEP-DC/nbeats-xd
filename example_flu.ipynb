{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## versions:\n",
    "## Python    : 3.11.5\n",
    "## numpy     : 1.26.0\n",
    "## torch     : 2.1.0\n",
    "## pandas    : 2.1.1\n",
    "\n",
    "# licensed under the Creative Commons - Attribution-NonCommercial 4.0\n",
    "# International license (CC BY-NC 4.0):\n",
    "# https://creativecommons.org/licenses/by-nc/4.0/. \n",
    "\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import shutil\n",
    "import datetime\n",
    "from typing import Dict, List, Optional\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as t\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from common.torch.ops import empty_gpu_cache\n",
    "from common.sampler import ts_dataset\n",
    "from common.torch.snapshots import SnapshotManager\n",
    "from experiments.trainer import trainer_var\n",
    "from experiments.model import generic_dec_var\n",
    "from models.exog import TCN_encoder\n",
    "\n",
    "from data_utils.forecast import tryJSON, Struct, read_config, default_settings, make_training_fn\n",
    "from data_utils.forecast import init_target_data, load_exog_data, make_training_fn, generate_quantiles\n",
    "from data_utils.forecast import pickle_results, read_pickle, output_figs\n",
    "from data_utils.flu import domain_defaults, specify_ensemble, custom_ensemble, output_df, append_forecasts\n",
    "from data_utils.flu import read_flu_data, read_weather_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "%config InlineBackend.figure_formats = [\"svg\"]\n",
    "plt.style.use(\"dark_background\")\n",
    "warnings.formatwarning = lambda message, category, *args, **kwargs: \"{}: {}\\n\".format(category.__name__, message)\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "#%load_ext watermark\n",
    "#%watermark -n -u -v -iv -w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(if needed) read latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx, _ = read_flu_data()\n",
    "#read_weather_data(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_config()` returns configuration settings that don't change between models within an ensemble\n",
    "\n",
    "gets values from `config.json` if available\n",
    "\n",
    "see comments in `data_utils/forecast.py` for an explanation of entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstate = read_config(\"config_flu.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can change the settings here or in `config.json`\n",
    "\n",
    "e.g., `rstate.cut` sets the train/test split index (None = train on all data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstate.cut = 447 #395 #432 #436 #None  #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`default_settings()` returns settings that can be changed between models within an ensemble\n",
    "\n",
    "gets defaults from `settings.json` if available\n",
    "\n",
    "see comments in `data_utils/forecast.py` for an explanation of entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = default_settings(\"settings_flu.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can change settings in json file or here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try increasing the learning rate when there's more training data\n",
    "#settings.init_LR = np.round(0.0001 + (rstate.cut - 901) * 4e-7, 7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will change `settings.exog_vars` below, to specify which exogenous predictors to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`domain_defaults()` is meant to be a user-defined function\n",
    "\n",
    "returns a struct with instructions for reading or generating exogenous variables\n",
    "\n",
    "see `data_utils/covid_hub.py` for an example/explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_specs = domain_defaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`exog_vars` specifies which exogenous predictors to use by default\n",
    "\n",
    "the predictors in `var_names` are loaded/generated and available to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`init_target_data()` reads in and optionally transforms target data\n",
    "\n",
    "sets timepoint indices and series identifiers; writes data to `rstate`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstate, settings = init_target_data(rstate, settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rstate.data_index` was set based on the index of `rstate.target_file`\n",
    "\n",
    "for exogenous data, the files and functions specified in `domain_defaults()` must generate data frames with the same index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstate.data_dir+\"/\"+rstate.target_file, rstate.data_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`load_exog_data()` appends exogenous predictors to rstate, using the data index generated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstate, settings = load_exog_data(rstate, settings, domain_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`settings.exog_vars` now has the defaults from domain_specs (if this was not set in `settings.json`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.exog_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the data has been read into `rstate` as a dict keyed by series name\n",
    "\n",
    "each series is a data frame with rows as timepoints and columns as variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstate.series_dfs[\"Maryland\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the name of the target column was set automatically by `init_target_data()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstate.target_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`make_training_fn()` returns a function that trains a model  (it closes over training data and config settings)\n",
    "\n",
    "the resulting function takes `settings` and returns mean & variance forecasts\n",
    "\n",
    "the forecasts are matrices with rows = series and columns = timepoints\n",
    "\n",
    "the trained models are saved in `rstate.snapshot_dir`\n",
    "\n",
    "the training function can be used on its own or called in a loop with different settings to generate an ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_fn = make_training_fn(rstate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set settings.cut_weights to increase training effort on rare events such as prominent peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def peak_cut_weights(rstate, settings):\n",
    "\n",
    "    ## use scipy find_peaks to find indices of qualifying peaks\n",
    "    idx_pre_peak = []; idx_immed_peak = []; idx_post_peak = []; idx_zeros = []; idx_highest_peak = []; idx_post_highest = [] #;series_peaks = []\n",
    "    for targ_sum in rstate.nat_targets:\n",
    "        peaks,_ = find_peaks(targ_sum,height=2.0,distance=settings.horizon)\n",
    "        #peaks,_ = find_peaks(targ_sum,height=2.0,prominence=0.75)\n",
    "        #series_peaks.append(peaks)\n",
    "        ## highest peak of each season\n",
    "        highest_peaks,_ = find_peaks(targ_sum,height=2.0,distance=25)\n",
    "\n",
    "        ## cut points that place a peak inside the forecast horizon\n",
    "        idx_pre_peak.append( [i for i in np.unique(np.concatenate([range(x - settings.horizon + 1, x) for x in peaks])) if (0 <= i < targ_sum.shape[0])] )\n",
    "        \n",
    "        ## n cutpoints before a peak\n",
    "        idx_immed_peak.append( [i for i in np.unique(np.concatenate([range(x - 3, x) for x in peaks])) if (0 <= i < targ_sum.shape[0])] )\n",
    "\n",
    "        ## n cutpoints before highest peak\n",
    "        idx_highest_peak.append( [i for i in np.unique(np.concatenate([range(x - 3, x) for x in highest_peaks])) if (0 <= i < targ_sum.shape[0])] )\n",
    "\n",
    "        ## cut points at a peak and a few points after\n",
    "        idx_post_peak.append( [i for i in np.unique(np.concatenate([range(x, x + 4) for x in peaks])) if (0 <= i < targ_sum.shape[0])] )\n",
    "\n",
    "        ## n cutpoints at and after highest peak\n",
    "        idx_post_highest.append( [i for i in np.unique(np.concatenate([range(x, x + 6) for x in highest_peaks])) if (0 <= i < targ_sum.shape[0])] )\n",
    "\n",
    "        ## points where the whole horizon is near zero\n",
    "        #idx_zeros.append( [i for i in range(targ_sum.shape[0]) if np.all(targ_sum[i:i+settings.horizon+1] < 0.25)] )\n",
    "        ## just points near zero\n",
    "        idx_zeros.append( [i for i in range(targ_sum.shape[0]) if targ_sum[i]<0.25] )\n",
    "\n",
    "    cut_weights = [None for _ in rstate.nat_targets]\n",
    "\n",
    "    for (i,targ_sum) in enumerate(rstate.nat_targets):\n",
    "        W = np.ones(targ_sum.shape[0])\n",
    "        ## careful of overwrite order:\n",
    "        #W[idx_post_peak[i]] = 1.0 #2.0 #4.0 #2.0\n",
    "        #W[idx_pre_peak[i]] = 2.0 #2.0\n",
    "        #W[idx_immed_peak[i]] = 1.0 #2.0\n",
    "\n",
    "        ## \"peakfinder\" model\n",
    "        W[idx_post_highest[i]] = 4.0 \n",
    "        W[idx_highest_peak[i]] = 8.0 \n",
    "\n",
    "        W[idx_zeros[i]] = 0.25 #0.1 # \n",
    "        cut_weights[i] = W\n",
    "\n",
    "    return cut_weights\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings.cut_weights = None\n",
    "\n",
    "settings.cut_weights = peak_cut_weights(rstate, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "targ_sum = rstate.nat_targets[i]\n",
    "_,ax=plt.subplots()\n",
    "plt.plot(targ_sum,linewidth=0.75);\n",
    "wts = settings.cut_weights[i];\n",
    "i0 = np.nonzero(wts<0.99)[0]\n",
    "i1 = np.nonzero(wts>1.01)[0]\n",
    "i2 = np.nonzero(wts>2.01)[0]\n",
    "i3 = np.nonzero(wts>4.01)[0]\n",
    "plt.plot(i0,targ_sum[i0],\".\",alpha=0.5,color=\"orangered\");\n",
    "plt.plot(i1,targ_sum[i1],\".\",color=\"white\");\n",
    "plt.plot(i2,targ_sum[i2],\".\",color=\"orange\");\n",
    "plt.plot(i3,targ_sum[i3],\"+\",color=\"magenta\");\n",
    "#plt.plot(series_peaks[i], targ_sum[series_peaks[i]],\"x\",alpha=0.66); #plt.plot(idx_zeros[i],targ_sum[idx_zeros[i]],\".\",alpha=0.5,color=\"orangered\");\n",
    "#plt.plot(idx_post_peak[i],targ_sum[idx_post_peak[i]],\".\",color=\"orange\"); #plt.plot(idx_pre_peak[i],targ_sum[idx_pre_peak[i]],\"+\",color=\"white\");\n",
    "#plt.plot(idx_immed_peak[i],targ_sum[idx_immed_peak[i]],\".\",color=\"white\"); #ax.set_xlim([120,220])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to use snapshot/pretrained model with no additional training, set iterations to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use snapshot/pretrained model, no additional training\n",
    "#settings.iterations = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to train an ensemble of models, we will generate a list of `settings`, one for each model\n",
    "\n",
    "`specify_ensemble` is a user-defined function that generates the list, based on info in `domain_specs`\n",
    "\n",
    "see `data_utils/covid_hub.py` for an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_specs.random_reps = 2\n",
    "\n",
    "## generate a list of settings structs having the desired variation for ensemble\n",
    "## save the list to rstate for posterity\n",
    "rstate.settings_list = specify_ensemble(settings, domain_specs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can also define some other ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting size of hidden layer based on size of lookback window:\n",
    "## (defined in flu.py)\n",
    "\n",
    "rstate.settings_list = custom_ensemble(settings, domain_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstate.settings_list[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(optional) a pretrained model file for each model in the ensemble\n",
    "\n",
    "each must have the same structure (lookback window, hidden dims, etc.) as the corresponding ensemble entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pretrained_list(pretrain_dir, specs):\n",
    "    file_list = []\n",
    "    for j in range(specs.random_reps):\n",
    "        for opt in specs.lookback_opts:\n",
    "            filename = \"flu24_\" + str(opt) + \"H_\" + str(j+1) + \".pt\"\n",
    "            file_list.append(os.path.join(pretrain_dir,filename))\n",
    "    return file_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstate.pretrained_models = [None for x in rstate.settings_list]\n",
    "\n",
    "pretrain_dir = None # \"flu_pretrained_2024\" # \n",
    "\n",
    "if pretrain_dir is not None:\n",
    "    rstate.pretrained_models = pretrained_list(os.path.join(rstate.data_dir,pretrain_dir), domain_specs)\n",
    "\n",
    "rstate.pretrained_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "empty dicts for storing the forecasts from each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_fc={}\n",
    "var_fc={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_gpu_cache() ## just in case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train each model in the ensemble and write its forecast to `mu_fc` and `var_fc` (keyed w/ a semi-descriptive name):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## ensemble loop\n",
    "for i, set_i in enumerate(rstate.settings_list):\n",
    "    model_name = rstate.output_prefix+\"_\"+str(i)\n",
    "    model_suffix = str(rstate.cut) if rstate.cut is not None else str(rstate.data_index[-1])\n",
    "    model_name = model_name+\"_\"+model_suffix\n",
    "    print(\"training \",model_name)\n",
    "    mu_fc[model_name], var_fc[model_name] = training_fn(model_name, set_i, rstate.pretrained_models[i]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forecast shape for each model is [series, time]\n",
    "\n",
    "ensemble the dict values using median across models\n",
    "\n",
    "write results to `rstate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mu_fc[\"ensemble\"] = np.median(np.stack([mu_fc[k] for k in mu_fc]),axis=0)\n",
    "var_fc[\"ensemble\"] = np.median(np.stack([var_fc[k] for k in var_fc]),axis=0)\n",
    "\n",
    "rstate.mu_fc = mu_fc\n",
    "rstate.var_fc = var_fc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if forecast targets are per-capita, need series weights for summing to national (per capita) forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rstate.series_weights is not None:\n",
    "    print(pd.DataFrame({\"state\":rstate.series_names,\"weight\":rstate.series_weights.squeeze()}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`generate_quantiles()` goes through each entry in `rstate.mu_fc` and `rstate.var_fc`\n",
    "\n",
    "and generates dicts containing forecast quantiles for each model (and \"ensemble\")\n",
    "\n",
    "see comments in `data_utils/forecast.py` for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstate = generate_quantiles(rstate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optional: save rstate, which contains all training data, forecasts, and ensemble settings\n",
    "\n",
    "`pickle_results()` writes it to output dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_results(rstate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot some forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_figs(rstate, rstate.settings_list[0].horizon, \n",
    "#[0,1,2,4], \n",
    "#[8,9,10,11], \n",
    "range(12),\n",
    " 70,\n",
    " colors=[\"white\",\"yellow\"],figsize=(5,3),plot_mean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save forecasts as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df,_ = output_df(rstate,0)\n",
    "df.query(\"location == 'US' and quantile=='mean'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append_forecasts(df, os.path.join(rstate.data_dir,\"forecast_plots.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete the trained models if we no longer need them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rstate.delete_models:\n",
    "    try:\n",
    "        shutil.rmtree(rstate.snapshot_dir)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "automate the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rstate(cut, settings, domain_specs, ensemble_fn=specify_ensemble, cut_weight_fn=None):\n",
    "    rstate = read_config(\"config_flu.json\")\n",
    "    rstate.cut = cut\n",
    "    \n",
    "    rstate, settings = init_target_data(rstate, settings)\n",
    "    rstate, settings = load_exog_data(rstate, settings, domain_specs)\n",
    "\n",
    "    if cut_weight_fn is not None: settings.cut_weights = cut_weight_fn(rstate, settings)\n",
    "\n",
    "    rstate.settings_list = ensemble_fn(settings, domain_specs)\n",
    "    rstate.pretrained_models = [None for x in rstate.settings_list]\n",
    "    \n",
    "    return rstate, settings\n",
    "\n",
    "\n",
    "def generate_ensemble(rstate, ens_fn=np.median):\n",
    "    mu_fc={}\n",
    "    var_fc={}\n",
    "    empty_gpu_cache()\n",
    "    training_fn = make_training_fn(rstate)\n",
    "\n",
    "    ## ensemble loop\n",
    "    for i, set_i in enumerate(rstate.settings_list):\n",
    "        model_name = rstate.output_prefix+\"_\"+str(i)\n",
    "        model_suffix = str(rstate.cut) if rstate.cut is not None else str(rstate.data_index[-1])\n",
    "        model_name = model_name+\"_\"+model_suffix\n",
    "        print(\"training \",model_name)\n",
    "        mu_fc[model_name], var_fc[model_name] = training_fn(model_name, set_i, rstate.pretrained_models[i]) \n",
    "\n",
    "    mu_fc[\"ensemble\"] = ens_fn(np.stack([mu_fc[k] for k in mu_fc]),axis=0)\n",
    "    var_fc[\"ensemble\"] = ens_fn(np.stack([var_fc[k] for k in var_fc]),axis=0)\n",
    "    rstate.mu_fc = mu_fc\n",
    "    rstate.var_fc = var_fc\n",
    "\n",
    "    rstate = generate_quantiles(rstate)\n",
    "\n",
    "    return rstate\n",
    "\n",
    "\n",
    "def delete_model_dir(rstate):\n",
    "    if rstate.delete_models:\n",
    "        try:\n",
    "            shutil.rmtree(rstate.snapshot_dir)\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## try adjusting the amount of training based on the amount of training data history\n",
    "## (lowering learning rate seems to work better than decreasing # of iterations)\n",
    "def adapt_iter(x):\n",
    "    return None#int(np.round(200 + (x - 901) * 2.0 / 3.0))\n",
    "\n",
    "def adapt_lr(x):\n",
    "    return None#np.round(0.0001 + (x - 901) * 4e-7, 7) \n",
    "\n",
    "def run_test(cut, random_reps=None, ensemble_fn=specify_ensemble, series_figs=[], n_iter=None, pretrain_list_fn=None, cut_weight_fn=None, ens_reduce=np.median, adj_iter=False, adj_LR=False):\n",
    "    ## if adj_*, train more when there is more data; otherwise use values from settings.json\n",
    "    settings = default_settings(\"settings_flu.json\")\n",
    "    #if adj_iter: settings.iterations = adapt_iter(cut)\n",
    "    #if adj_LR: settings.init_LR = adapt_lr(cut)\n",
    "    if n_iter is not None: settings.iterations = n_iter\n",
    "\n",
    "    domain_specs = domain_defaults()\n",
    "    if random_reps is not None: domain_specs.random_reps = random_reps\n",
    "    \n",
    "    rstate, settings = init_rstate(cut, settings, domain_specs, ensemble_fn, cut_weight_fn)\n",
    "\n",
    "    if pretrain_list_fn is not None:\n",
    "        rstate.pretrained_models = pretrain_list_fn(rstate.data_dir, domain_specs)\n",
    "\n",
    "    rstate = generate_ensemble(rstate, ens_reduce)\n",
    "\n",
    "    pickle_results(rstate)\n",
    "    output_figs(rstate, rstate.settings_list[0].horizon, \n",
    "                series_figs, \n",
    "                70,\n",
    "                colors=[\"white\",\"yellow\"],figsize=(5,3),plot_mean=True)\n",
    "\n",
    "    df, date_stamp = output_df(rstate,0)\n",
    "\n",
    "    delete_model_dir(rstate)\n",
    "    \n",
    "    return (df, date_stamp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graph training losses\n",
    "\n",
    "note, ensembling not-quite-converged models seems to work better than running more iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_losses(pickle_file,ylim=None):\n",
    "    rstate = read_pickle(pickle_file)\n",
    "    model_prefix = rstate.output_prefix\n",
    "    model_suffix = str(rstate.cut) if rstate.cut is not None else str(rstate.data_index[-1])\n",
    "    _, ax = plt.subplots(nrows=len(rstate.settings_list),ncols=2,figsize=[8,2*len(rstate.settings_list)])\n",
    "    for i, set_i in enumerate(rstate.settings_list):\n",
    "        model_name =  model_prefix+\"_\"+str(i)+\"_\"+model_suffix\n",
    "        total_iter = set_i.iterations\n",
    "        snapshot_manager = SnapshotManager(snapshot_dir=os.path.join(rstate.snapshot_dir, model_name), total_iterations=total_iter)\n",
    "        ldf = snapshot_manager.load_training_losses()\n",
    "        vdf = snapshot_manager.load_validation_losses()\n",
    "        ax[i,0].plot(ldf)\n",
    "        ax[i,1].plot(vdf)\n",
    "        ax[i,1].set_ylim(ylim)\n",
    "    #plt.show()\n",
    "    plt.savefig(os.path.join(rstate.output_dir , \"losses_\"+model_prefix+\"_\"+model_suffix+\".png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(os.path.join(\"fluview\", \"output\", \"flu_395.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(os.path.join(\"fluview\", \"output\", \"flu_447.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_test(cut=436, random_reps=3, ensemble_fn=custom_ensemble, series_figs=range(12), cut_weight_fn=peak_cut_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_losses(os.path.join(\"fluview\", \"output\", \"flu_436.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre23test(data_dir, specs):\n",
    "    file_list = []\n",
    "    i = 0\n",
    "    for j in range(specs.random_reps):\n",
    "        for opt in specs.lookback_opts:\n",
    "            filepath = os.path.join(\"flu_\"+str(i)+\"_395\",\"model\")\n",
    "            file_list.append(os.path.join(data_dir,\"snapshots\",filepath))\n",
    "            i = i + 1\n",
    "    return file_list\n",
    "\n",
    "def pre24test(data_dir, specs):\n",
    "    file_list = []\n",
    "    i = 0\n",
    "    for j in range(specs.random_reps):\n",
    "        for opt in specs.lookback_opts:\n",
    "            filepath = os.path.join(\"flu_\"+str(i)+\"_447\",\"model\")\n",
    "            file_list.append(os.path.join(data_dir,\"snapshots\",filepath))\n",
    "            i = i + 1\n",
    "    return file_list\n",
    "\n",
    "def pre24pf(data_dir, specs):\n",
    "    file_list = []\n",
    "    for j in range(specs.random_reps):\n",
    "        for opt in specs.lookback_opts:\n",
    "            filepath = \"flu24_\"+str(opt)+\"H_\"+str(j+1)+\".pt\"\n",
    "            file_list.append(os.path.join(data_dir,\"peakfinder_pretrained\",filepath))\n",
    "    return file_list\n",
    "\n",
    "def pre24ond(data_dir, specs):\n",
    "    file_list = []\n",
    "    for j in range(specs.random_reps):\n",
    "        for opt in specs.lookback_opts:\n",
    "            filepath = \"flu24_\"+str(opt)+\"H_\"+str(j+1)+\".pt\"\n",
    "            file_list.append(os.path.join(data_dir,\"orig_noise_downwt_pretrained\",filepath))\n",
    "    return file_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = \"forecast_peakfinder\"\n",
    "df,_ = run_test(None, 3, custom_ensemble, [], 0, pre24pf)\n",
    "append_forecasts(df, os.path.join(\"fluview\",csv_name+\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = \"forecast_orig_noise_down\"\n",
    "df,_ = run_test(None, 3, custom_ensemble, [], 0, pre24ond)\n",
    "append_forecasts(df, os.path.join(\"fluview\",csv_name+\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = \"test\"\n",
    "last_idx = 473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cut in range(415,448):\n",
    "    df,_ = run_test(cut, 3, custom_ensemble, [], 0, pre23test);\n",
    "    append_forecasts(df, os.path.join(\"fluview\",csv_name+\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copyfile(os.path.join(\"fluview\",csv_name+\".csv\"), os.path.join(\"fluview\",csv_name+\"_2023.csv\"))\n",
    "\n",
    "for cut in range(467,last_idx):\n",
    "    df,_ = run_test(cut, 3, custom_ensemble, [], 0, pre24test)\n",
    "    append_forecasts(df, os.path.join(\"fluview\",csv_name+\".csv\"))\n",
    "    \n",
    "df,_ = run_test(None, 3, custom_ensemble, [], 0, pre24test)\n",
    "append_forecasts(df, os.path.join(\"fluview\",csv_name+\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rstate.delete_models = True\n",
    "#delete_model_dir(rstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pull pretrained models out of snapshot directories\n",
    "\n",
    "model_dir = \"snapshots\"\n",
    "n = 2\n",
    "opts = [2,3,4,5]\n",
    "idx = 4\n",
    "\n",
    "i = 0\n",
    "for j in range(n):\n",
    "    for opt in opts:\n",
    "        filepath = os.path.join(\"fluview\",model_dir,\"flu_\"+str(i)+\"_447\",\"model\")\n",
    "        dest = os.path.join(\"fluview\",model_dir,\"flu24_\"+str(opt)+\"H_\"+str(j+idx)+\".pt\")\n",
    "        shutil.copyfile(filepath, dest)\n",
    "        i = i + 1\n",
    "i = 0\n",
    "for j in range(n):\n",
    "    for opt in opts:\n",
    "        filepath = os.path.join(\"fluview\",model_dir,\"flu_\"+str(i)+\"_395\",\"model\")\n",
    "        dest = os.path.join(\"fluview\",model_dir,\"flu23_\"+str(opt)+\"H_\"+str(j+idx)+\".pt\")\n",
    "        shutil.copyfile(filepath, dest)\n",
    "        i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
